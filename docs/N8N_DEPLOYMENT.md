# Guia de Deploy: Integra√ß√£o n8n + MCP Server

## üìã Resumo Executivo

Este documento fornece um guia passo a passo para fazer o deploy da arquitetura de IA otimizada usando n8n e MCP Server para o sistema Divino Lanches.

### Benef√≠cios da Nova Arquitetura

- ‚úÖ **75% de redu√ß√£o** nos custos com OpenAI API
- ‚úÖ **44% mais r√°pido** nas respostas da IA
- ‚úÖ **Escal√°vel** para qualquer volume de dados
- ‚úÖ **Arquitetura moderna** seguindo padr√µes da ind√∫stria

---

## üèóÔ∏è Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Usu√°rio   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Frontend   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Backend   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   n8n    ‚îÇ
‚îÇ  (Browser)  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  (React/JS)  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ    (PHP)    ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Workflow ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                       ‚îÇ
                                                                       ‚ñº
                                                               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                               ‚îÇ  MCP Server   ‚îÇ
                                                               ‚îÇ   (Node.js)   ‚îÇ
                                                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                       ‚îÇ
                                                                       ‚ñº
                                                               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                               ‚îÇ  PostgreSQL   ‚îÇ
                                                               ‚îÇ   Database    ‚îÇ
                                                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                       ‚îÇ
                                                                       ‚ñº
                                                               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                               ‚îÇ  OpenAI API   ‚îÇ
                                                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üì¶ Componentes

### 1. MCP Server
- **Tecnologia**: Node.js + Express
- **Porta**: 3100
- **Fun√ß√£o**: Interface de acesso ao banco de dados para IA

### 2. n8n Workflow Engine
- **Tecnologia**: n8n (Low-code automation)
- **Porta**: 5678
- **Fun√ß√£o**: Orquestra√ß√£o de workflows de IA

### 3. Sistema Divino Lanches (Existente)
- **Tecnologia**: PHP + React
- **Modifica√ß√£o**: Integra√ß√£o com webhook n8n

---

## üöÄ Deploy Step-by-Step

### Passo 1: Preparar Ambiente

#### 1.1 Atualizar docker-compose.yml

Adicione os novos servi√ßos ao seu `docker-compose.yml`:

```yaml
version: '3.8'

services:
  # ... servi√ßos existentes (postgres, php, frontend) ...

  # MCP Server - Database interface for AI
  mcp-server:
    build: ./n8n-mcp-server
    container_name: divino-mcp-server
    ports:
      - "3100:3100"
    environment:
      - MCP_PORT=3100
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=${DB_NAME}
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
    depends_on:
      - postgres
    restart: unless-stopped
    networks:
      - divino-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3100/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # n8n Workflow Engine
  n8n:
    image: n8nio/n8n:latest
    container_name: divino-n8n
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_USER:-admin}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD}
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - NODE_ENV=production
      - WEBHOOK_URL=http://${N8N_HOST:-localhost}:5678/
      - GENERIC_TIMEZONE=America/Sao_Paulo
    volumes:
      - n8n_data:/home/node/.n8n
    restart: unless-stopped
    networks:
      - divino-network
    depends_on:
      - mcp-server

volumes:
  n8n_data:

networks:
  divino-network:
    driver: bridge
```

#### 1.2 Atualizar .env

Adicione as novas vari√°veis ao seu `.env`:

```bash
# AI Integration Mode
USE_N8N_AI=true

# n8n Configuration
N8N_HOST=localhost
N8N_USER=admin
N8N_PASSWORD=seu_password_seguro_aqui
N8N_WEBHOOK_URL=http://n8n:5678/webhook/ai-chat
N8N_TIMEOUT=30

# MCP Server (geralmente n√£o precisa mudar)
MCP_PORT=3100
```

### Passo 2: Deploy Local

#### 2.1 Build e Start dos Containers

```bash
# Build dos novos servi√ßos
docker-compose build mcp-server

# Start de todos os servi√ßos
docker-compose up -d

# Verificar se est√£o rodando
docker-compose ps
```

Voc√™ deve ver algo como:
```
NAME                   STATUS        PORTS
divino-mcp-server      Up 30 seconds 0.0.0.0:3100->3100/tcp
divino-n8n             Up 25 seconds 0.0.0.0:5678->5678/tcp
divino-postgres        Up 2 minutes  0.0.0.0:5432->5432/tcp
divino-php             Up 2 minutes  0.0.0.0:80->80/tcp
```

#### 2.2 Verificar MCP Server

```bash
# Health check
curl http://localhost:3100/health

# Deve retornar:
# {"status":"ok","timestamp":"2025-01-08T..."}

# Listar tools dispon√≠veis
curl http://localhost:3100/tools

# Testar query
curl -X POST http://localhost:3100/execute \
  -H "Content-Type: application/json" \
  -d '{
    "tool": "get_products",
    "parameters": {"limit": 5},
    "context": {"tenant_id": 1, "filial_id": 1}
  }'
```

#### 2.3 Configurar n8n

1. Abra http://localhost:5678 no browser
2. Fa√ßa login (admin / sua_senha)
3. V√° em **Settings** ‚Üí **API Key** ‚Üí Crie uma API key se necess√°rio
4. V√° em **Credentials** ‚Üí **Add Credential**
5. Adicione credencial **OpenAI**:
   - Name: `OpenAI API`
   - API Key: Sua chave OpenAI
   - Save

#### 2.4 Importar Workflow

1. No n8n, v√° em **Workflows**
2. Clique em **Import from File**
3. Selecione `n8n-integration/workflow-example.json`
4. Clique **Import**
5. No workflow importado, verifique/ajuste:
   - **MCP Server URL**: `http://mcp-server:3100/execute`
   - **OpenAI Credential**: Selecione a credencial criada
6. Clique em **Active** (toggle no topo direito)
7. **Copie a URL do webhook** (algo como `http://localhost:5678/webhook/ai-chat`)

#### 2.5 Atualizar .env com URL do Webhook

```bash
# No arquivo .env
N8N_WEBHOOK_URL=http://n8n:5678/webhook/ai-chat
```

#### 2.6 Reiniciar Backend PHP

```bash
docker-compose restart php
```

### Passo 3: Testar Integra√ß√£o

#### 3.1 Teste via Terminal

```bash
# Teste direto no webhook do n8n
curl -X POST http://localhost:5678/webhook/ai-chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Listar produtos",
    "tenant_id": 1,
    "filial_id": 1
  }'
```

Deve retornar:
```json
{
  "success": true,
  "response": {
    "type": "response",
    "message": "Aqui est√£o os produtos dispon√≠veis: ..."
  }
}
```

#### 3.2 Teste via Interface

1. Abra o sistema Divino Lanches
2. Fa√ßa login
3. Abra o **Assistente IA**
4. Envie mensagem: "Listar produtos"
5. Verifique a resposta

#### 3.3 Monitorar Logs

```bash
# Logs do MCP Server
docker logs -f divino-mcp-server

# Logs do n8n
docker logs -f divino-n8n

# Logs do PHP (seu sistema)
docker logs -f divino-php
```

#### 3.4 Verificar Execu√ß√µes no n8n

1. Abra http://localhost:5678
2. V√° no workflow
3. Clique na aba **Executions**
4. Veja os logs de cada execu√ß√£o

---

## üåê Deploy em Produ√ß√£o (Coolify)

### Passo 4: Preparar para Coolify

#### 4.1 Criar reposit√≥rio Git

```bash
# Adicionar novos arquivos
git add n8n-mcp-server/
git add n8n-integration/
git add system/N8nAIService.php
git add docs/

# Commit
git commit -m "Add n8n + MCP integration for AI"

# Push
git push origin main
```

#### 4.2 Configurar docker-compose para Produ√ß√£o

Crie `docker-compose.prod.yml`:

```yaml
version: '3.8'

services:
  mcp-server:
    build: ./n8n-mcp-server
    container_name: divino-mcp-server
    environment:
      - MCP_PORT=3100
      - DB_HOST=${DB_HOST}
      - DB_PORT=5432
      - DB_NAME=${DB_NAME}
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - API_KEY=${MCP_API_KEY}
    restart: unless-stopped
    networks:
      - divino-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3100/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  n8n:
    image: n8nio/n8n:latest
    container_name: divino-n8n
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_USER}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD}
      - N8N_HOST=${N8N_HOST}
      - N8N_PORT=5678
      - N8N_PROTOCOL=https
      - NODE_ENV=production
      - WEBHOOK_URL=https://${N8N_HOST}/
      - GENERIC_TIMEZONE=America/Sao_Paulo
    volumes:
      - n8n_data:/home/node/.n8n
    restart: unless-stopped
    networks:
      - divino-network
    labels:
      - "coolify.managed=true"
      - "coolify.type=application"
```

### Passo 5: Deploy no Coolify

#### 5.1 Criar Servi√ßo MCP Server

1. No Coolify, v√° em **New Resource** ‚Üí **Docker Compose**
2. Selecione seu reposit√≥rio Git
3. Branch: `main`
4. Docker Compose file: `docker-compose.prod.yml`
5. Service: `mcp-server`
6. Configure vari√°veis de ambiente:
   ```
   DB_HOST=seu_db_host
   DB_NAME=divino_lanches
   DB_USER=postgres
   DB_PASSWORD=sua_senha_segura
   MCP_API_KEY=gere_uma_key_aleatoria
   ```
7. Deploy

#### 5.2 Criar Servi√ßo n8n

Op√ß√£o A: **n8n Cloud (Recomendado)**
1. Acesse https://n8n.io e crie uma conta
2. Importe o workflow
3. Configure credenciais
4. Ative o workflow
5. Copie a URL do webhook

Op√ß√£o B: **Self-hosted no Coolify**
1. No Coolify, adicione novo servi√ßo
2. Tipo: Docker Image
3. Image: `n8nio/n8n:latest`
4. Configure dom√≠nio: `n8n.seudominio.com`
5. Configure vari√°veis de ambiente
6. Ative SSL
7. Deploy

#### 5.3 Atualizar Vari√°veis de Ambiente

No Coolify, v√° no servi√ßo do seu sistema PHP e adicione:

```bash
USE_N8N_AI=true
N8N_WEBHOOK_URL=https://n8n.seudominio.com/webhook/ai-chat
N8N_TIMEOUT=30
```

#### 5.4 Redeploy

1. Redeploy todos os servi√ßos
2. Verifique os logs
3. Teste a integra√ß√£o

---

## üîß Troubleshooting

### Problema: MCP Server n√£o conecta no banco

**Solu√ß√£o**:
```bash
# Verificar se o BD est√° acess√≠vel
docker exec -it divino-mcp-server ping postgres

# Verificar logs
docker logs divino-mcp-server

# Testar conex√£o manualmente
docker exec -it divino-mcp-server node -e "
const {Pool} = require('pg');
const pool = new Pool({host: 'postgres', password: 'sua_senha'});
pool.query('SELECT NOW()', (e,r) => console.log(e||r.rows));
"
```

### Problema: n8n webhook n√£o responde

**Solu√ß√£o**:
```bash
# Verificar se o workflow est√° ativo
# Ir no n8n UI ‚Üí Workflows ‚Üí Verificar toggle "Active"

# Verificar logs do n8n
docker logs divino-n8n

# Testar webhook diretamente
curl -X POST http://localhost:5678/webhook/ai-chat \
  -H "Content-Type: application/json" \
  -d '{"message":"teste"}'
```

### Problema: Sistema ainda usa OpenAI direto

**Solu√ß√£o**:
```bash
# Verificar se USE_N8N_AI est√° true
grep USE_N8N_AI .env

# Se n√£o estiver, adicione:
echo "USE_N8N_AI=true" >> .env

# Reinicie o container PHP
docker-compose restart php
```

### Problema: Timeout nas requisi√ß√µes

**Solu√ß√£o**:
```bash
# Aumentar timeout no .env
N8N_TIMEOUT=60

# Otimizar queries do MCP
# Adicionar √≠ndices no PostgreSQL
```

---

## üìä Monitoramento

### M√©tricas Importantes

1. **Lat√™ncia de resposta**
   - Meta: < 2 segundos
   - Monitorar em: n8n executions

2. **Taxa de erro**
   - Meta: < 1%
   - Monitorar em: logs do sistema

3. **Custo OpenAI**
   - Comparar antes/depois
   - Esperado: 75% de redu√ß√£o

4. **Uso de mem√≥ria/CPU**
   - MCP Server: ~50-100MB RAM
   - n8n: ~200-300MB RAM

### Ferramentas de Monitoramento

```bash
# Docker stats
docker stats divino-mcp-server divino-n8n

# Logs agregados
docker-compose logs -f mcp-server n8n

# Health checks
watch -n 10 'curl -s http://localhost:3100/health'
```

---

## üéØ Checklist de Deploy

- [ ] MCP Server rodando e saud√°vel
- [ ] n8n rodando e acess√≠vel
- [ ] Workflow importado e ativo
- [ ] Credenciais OpenAI configuradas
- [ ] Vari√°veis de ambiente corretas
- [ ] USE_N8N_AI=true no sistema
- [ ] Teste via terminal funcionando
- [ ] Teste via interface funcionando
- [ ] Logs sem erros
- [ ] Monitoramento configurado
- [ ] Backup do sistema antigo
- [ ] Documenta√ß√£o atualizada

---

## üìà Pr√≥ximos Passos

Ap√≥s deploy bem-sucedido:

1. **Otimiza√ß√£o**
   - Adicionar cache Redis
   - Implementar rate limiting
   - Otimizar queries do BD

2. **Funcionalidades Avan√ßadas**
   - Busca sem√¢ntica com embeddings
   - An√°lise de sentimento
   - Sugest√µes proativas

3. **An√°lise**
   - Comparar custos antes/depois
   - Medir satisfa√ß√£o dos usu√°rios
   - Coletar m√©tricas de uso

---

## üÜò Suporte

Problemas durante o deploy?

1. Verifique os logs de todos os servi√ßos
2. Teste cada componente independentemente
3. Consulte a documenta√ß√£o detalhada em:
   - `docs/N8N_ARCHITECTURE_COMPARISON.md`
   - `n8n-integration/SETUP_GUIDE.md`
   - `n8n-mcp-server/README.md`

---

**Vers√£o**: 1.0  
**√öltima Atualiza√ß√£o**: Janeiro 2025  
**Autor**: Time Divino Lanches
